# OLMap - Django Backend
# Tech stack: Django REST Framework, PostgreSQL, Gunicorn

image:
  repository: ghcr.io/forumviriumhelsinki/olmap-backend
  tag: "0.1.0"  # Updated by ArgoCD Image Updater

# Migration job image - tracked separately for visibility
migrations:
  image:
    repository: ghcr.io/forumviriumhelsinki/olmap-backend
    tag: "0.1.0"  # Updated by ArgoCD Image Updater

imagePullSecrets:
- name: ghcr-login-secret

replicaCount: 1

# Service account with Workload Identity for Cloud SQL IAM authentication
serviceAccount:
  create: true
  name: olmap-backend
  annotations:
    iam.gke.io/gcp-service-account: olmap@fvh-project-containers-etc.iam.gserviceaccount.com

# Cloud SQL Proxy sidecar (runs continuously alongside the app)
initContainers:
- name: cloud-sql-proxy
  image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.19.0
  restartPolicy: Always  # Makes it a sidecar in K8s 1.28+
  args:
  - "--structured-logs"
  - "--port=5432"
  - "--auto-iam-authn"
  - "fvh-project-containers-etc:europe-north1:fvh-postgres"
  securityContext:
    runAsNonRoot: true
    runAsUser: 65532
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
      - ALL
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 100m
      memory: 128Mi

# Security context for Kyverno policy compliance
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  fsGroup: 1000
  seccompProfile:
    type: RuntimeDefault

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false  # Django needs writable filesystem
  runAsNonRoot: true
  runAsUser: 1000
  capabilities:
    drop:
    - ALL

# Service configuration
service:
  type: ClusterIP
  port: 8000
  targetPort: 8000

# Ingress configuration
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
  - host: api.olmap.dataportal.fi
    paths:
    - path: /
      pathType: ImplementationSpecific
  tls:
  - hosts:
    - api.olmap.dataportal.fi
    secretName: olmap-backend-tls  # pragma: allowlist secret

# Health checks
livenessProbe:
  httpGet:
    path: /health/
    port: 8000
  initialDelaySeconds: 30
  periodSeconds: 30
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /health/
    port: 8000
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Environment variables
env:
  # Database configuration via Cloud SQL Proxy with IAM authentication
  SQL_ENGINE:
    value: "django.db.backends.postgresql"
  SQL_HOST:
    value: "127.0.0.1"
  SQL_PORT:
    value: "5432"
  POSTGRES_DB:
    value: "olmap"
  POSTGRES_USER:
    value: "olmap@fvh-project-containers-etc.iam"
  # Django settings
  DJANGO_DEBUG:
    value: "False"
  DJANGO_ALLOWED_HOSTS:
    value: "api.olmap.dataportal.fi,citylogistiikka.fvh.io,localhost"
  # Secret key from External Secrets
  DJANGO_SECRET_KEY:
    valueFrom:
      secretKeyRef:
        name: olmap-secrets
        key: DJANGO_SECRET_KEY
  # Sentry error tracking
  SENTRY_DSN:
    valueFrom:
      secretKeyRef:
        name: olmap-secrets
        key: SENTRY_DSN
  SENTRY_ENVIRONMENT:
    value: "production"

# Resource allocation
resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

# Volumes for writable directories
volumes:
- name: tmp
  emptyDir: {}
- name: static
  emptyDir: {}

volumeMounts:
- name: tmp
  mountPath: /tmp
- name: static
  mountPath: /app/staticfiles

# External Secrets configuration (secrets from GCP Secret Manager)
externalSecret:
  enabled: true
  name: olmap-external-secret
  refreshInterval: 1h
  secretStoreRef:
    kind: ClusterSecretStore
    name: gcp-store
  target:
    name: olmap-secrets
    creationPolicy: Owner
  data:
  - secretKey: DJANGO_SECRET_KEY  # pragma: allowlist secret
    remoteRef:
      key: olmap-django-secret-key
  - secretKey: SENTRY_DSN  # pragma: allowlist secret
    remoteRef:
      key: sentry_dsn_olmap

# Database migrations (Helm hook - runs before deployment)
migrations:
  enabled: true
  command: ['python']
  args: ['manage.py', 'migrate', '--noinput']
  # Cloud SQL Proxy sidecar for the migration job
  initContainers:
  - name: cloud-sql-proxy
    image: gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.19.0
    restartPolicy: Always
    args:
    - "--structured-logs"
    - "--port=5432"
    - "--auto-iam-authn"
    - "fvh-project-containers-etc:europe-north1:fvh-postgres"
    securityContext:
      runAsNonRoot: true
      runAsUser: 65532
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop:
        - ALL
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        cpu: 100m
        memory: 128Mi
  env:
  - name: SQL_ENGINE
    value: 'django.db.backends.postgresql'
  - name: SQL_HOST
    value: '127.0.0.1'
  - name: SQL_PORT
    value: '5432'
  - name: POSTGRES_DB
    value: 'olmap'
  - name: POSTGRES_USER
    value: 'olmap@fvh-project-containers-etc.iam'
  - name: DJANGO_SECRET_KEY
    valueFrom:
      secretKeyRef:
        name: olmap-secrets
        key: DJANGO_SECRET_KEY
  waitForDatabase:
    enabled: true
    host: 127.0.0.1
    port: 5432
    user: 'olmap@fvh-project-containers-etc.iam'
    timeout: 300
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 200m
      memory: 256Mi

# KEDA scaling configuration (office hours: Mon-Fri 7am-6pm Helsinki)
keda:
  enabled: true
  minReplicaCount: 0
  maxReplicaCount: 2
  pollingInterval: 30
  cooldownPeriod: 300
  triggers:
  - type: cron
    metadata:
      timezone: Europe/Helsinki
      start: 0 7 * * 1-5
      end: 0 18 * * 1-5
      desiredReplicas: "1"
